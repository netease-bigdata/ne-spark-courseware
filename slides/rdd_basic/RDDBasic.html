
<html>
  <head>
    <title>RDD概述</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        ffont-weight: 400;
        margin-bottom: 0;
      }
      .remark-slide-content h1 { font-size: 3em; }
      .remark-slide-content h2 { font-size: 2em; }
      .remark-slide-content h3 { font-size: 1.6em; }
      .footnote {
        position: absolute;
        bottom: 3em;
      }
      li p { line-height: 1.25em; }
      .red { color: #fa0000; }
      .large { font-size: 2em; }
      a, a > code {
        color: rgb(249, 38, 114);
        text-decoration: none;
      }
      code {
        background: #e7e8e2;
        border-radius: 5px;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .remark-code-line-highlighted     { background-color: #373832; }
      .pull-left {
        float: left;
        width: 47%;
      }
      .pull-right {
        float: right;
        width: 47%;
      }
      .pull-right ~ p {
        clear: both;
      }
      #slideshow .slide .content code {
        font-size: 0.8em;
      }
      #slideshow .slide .content pre code {
        font-size: 0.9em;
        padding: 15px;
      }
      .inverse {
        background: #272822;
        color: #777872;
        text-shadow: 0 0 20px #333;
      }
      .inverse h1, .inverse h2 {
        color: #fff;
        line-height: 0.8em;
      }
    
      /* Slide-specific styling */
      #slide-inverse .footnote {
        bottom: 12px;
        left: 20px;
      }
      #slide-how .slides {
        font-size: 0.9em;
        position: absolute;
        top:  151px;
        right: 140px;
      }
      #slide-how .slides h3 {
        margin-top: 0.2em;
      }
      #slide-how .slides .first, #slide-how .slides .second {
        padding: 1px 20px;
        height: 90px;
        width: 120px;
        -moz-box-shadow: 0 0 10px #777;
        -webkit-box-shadow: 0 0 10px #777;
        box-shadow: 0 0 10px #777;
      }
      #slide-how .slides .first {
        background: #fff;
        position: absolute;
        top: 20%;
        left: 20%;
        z-index: 1;
      }
      #slide-how .slides .second {
        position: relative;
        background: #fff;
        z-index: 0;
      }
    
      /* Two-column layout */
      .left-column {
        color: #777;
        width: 20%;
        height: 92%;
        float: left;
      }
      .left-column h2:last-of-type, .left-column h3:last-of-type {
        color: #000;
      }
      .right-column {
        width: 75%;
        float: right;
        padding-top: 1em;
      }
    
      /* Two-column layout inverse*/
      .left-column-inverse {
        color: #777;
        width: 20%;
        height: 92%;
        float: left;
      }
      .left-column-inverse h2:last-of-type, .left-column-inverse h3:last-of-type {
        color: #fff;
      }
      .right-column-inverse {
        width: 75%;
        float: right;
        padding-top: 1em;
      }
      .right-column-inverse h2, .right-column-inverse h3, .right-column-inverse h4 {
        color: #fff;
      }
    </style>
  </head>
  <body>
    <textarea id="source">

class: center, middle, inverse

## [NetEase Spark Courses](https://netease-bigdata.github.io/ne-spark-courseware/)

<br>
<br>
<br>
<br>

## Spark RDD 概述

<br>
<br>
<br>
<br>

<img style="zoom: 1.0" src="../../imgs/mammut.png"  align="bottom" />

???
备注：标题 <br>
帮助信息：在网页端按H键可进入帮助页面

---

class:  center,inverse
name: rdd

  # Agenda
  ## -
  ** About Me **<br>
  ## -
  **  RDD定义及特点  **<br>
  ** RDD Operations **<br>
  ** RDD 依赖 **<br>
  ** RDD 与 Task **<br>
  ** RDD Persist **<br>
  ** 相关链接 **<br>

---
class: 
name:
.left-column[
## About Me
]
.right-column[
## 王斐

2018年校招加入网易，硕士期间研究Spark平台内存优化，目前在杭州研究院-数据科学中心负责Spark平台开发相关工作。
]
---


class:
name:

.left-column[
### RDD定义及特点
#### RDD定义

]
.right-column[
RDD(Resilient Distributed Datasets),弹性分布式数据集，是对分布式内存的抽象。
<figure class="half">
    <img src="../../imgs/rdd_basics/rdd-inmemory.png" width="45%" height="40%">
    <img src="../../imgs/rdd_basics/rdd-itr.png" width="45%"  height="40%">
</figure>
]

---
class:
name:
.left-column[
### RDD定义及特点
#### RDD定义
#### RDD特点

]
.right-column[
#### 只读，不可变
#### 分区
#### 血缘
#### 延迟计算
<figure class="half">
    <img src="../../imgs/rdd_basics/rdd-feature.png" width="100%"  height="35%">
</figure>

]



---
class:
name:
.left-column[
## RDD Operations
<!-- ### transformation & action
 -->
 ### transformation
]
.right-column[
transformation：从数据源生成RDD或者对已存在的RDD进行转换生成新RDD。

  | transformation | Meaning |
| -- | :-----: |
|  textFile/objectFile| 从数据源生成RDD|
| map(func)      | 对每条record进行函数计算 |
| filter(func) | 过滤掉符合条件的records |
| flatMap(func) | 将records的按照规则进行展开 |
| mapPartitions(func) | 以RDD的每个分区进行函数计算 |
| mapPartitionsWithIndex(func) |   对分区操作，提供partitionId参数      |
| sample(withReplacement, fraction, seed) | 返回一个子集 |
| intersection(otherDataset) | 返回两个RDD的交集        |
| distinct([numPartitions])) |   返回一个不包含重复record的数据集      |
| groupByKey([numPartitions]) | 对(k,v)类型records按照key进行聚合 |
| reduceByKey(func, [numPartitions]) | 对(k,v)类型records按照key进行合并 |
| aggregateByKey(zeroValue)(seqOp, combOp, [numPartitions]) |  先对数据按照分区聚合，然后再按照key值合并    |
| sortByKey | 对(k,v)类型records按照key进行排序 |
| union(otherDataset) | 直接将两个RDD的分区进行联合 |
| join | (k,v) join(k,w)=>(k,(v,w))|
| cogroup |   （k,v) coGroup(k,w)=>(k,seq(v),seq(w))|
| cartesian(otherDataset) | 笛卡尔积计算 |
| coalesce(numPartitions) | 重新分区 |
| repartition(numPartitions) | 重新分区 |
| repartitionAndSortWithinPartitions(partitioner) | 重新分区，且在分区内进行排序 |


]

---
class:
name:
.left-column[
## RDD Operations
### transformation
]
.right-column[
- transforamtion算子只是提供了一个并行的语义。

- API隐藏了数据划分、并行、容错等复杂的框架代码。

- 算子里面参数为用户自定义的函数(UDF)，该函数为一个串行函数，根据算子的语义对RDD中的数据按照语义的<font color=#A52A2A size=4 >**操作粒度**</font>进行操作。

1. rdd1.mapValues(s=> s*2)
2. def func1( i:Int):Int={ i*2}
   
   rdd1.mapValues (func1)

]
---
class:
name:
.left-column[
## RDD Operations
<!-- ### transformation & action
 -->
 ### transformation
]
.right-column[

- 对整条数据操作

  map, flatMap, filter

- 对(key, value) 中的value操作

  mapValues

- 对整个分区数据操作

  mapPartitions,mapPartitionsWithIndex

- 对多个RDD进行操作

  join, union, coGroup

- 重新分区

  repartition, coalesce 



]

---

class:
name:
.left-column[
## RDD Operations
### transformation
### action

]
.right-column[

Action:得到一个结果，或者将RDD存入磁盘。

| Action | Meaning |
| :----------: | :--------------------------------------: |
| countByKey() | 返回每个(k,count(k))，即每个key的个数 |
| reduce(func) | 将所有数据按照func进行聚合 |
|   take(n)    | 返回数据集的前N个数据 |
|  collect()   | 将所有数据提取到driver上，转换成一个数组 |
|   count()    | 获得数据集的数据条数 |
|   first()    | 返回数据集的第一个数据 |
|foreach(func) | 对每个数据进行操作 |
| takeOrdered(n, [ordering])  | 返回排序后数据集的前n个数据 |
| takeSample(withReplacement, num, [seed]) | 根据seed进行抽样，获得num个数据 |
|  saveAsTextFile(path)  | 保存为text文件 |
| saveAsObjectFile(path) | 保存为object文件 |
]

---

class:
name:
.left-column[
## RDD Operations
### transformation
### action
### 合理使用算子
]
.right-column[

- 例子： 一个RDD有10个分区，每个分区有1000条数据。对每条数据进行function操作。

  map算子，调用function 10000次

  mapPartitions算子，调用function10次，但是每次处理一个分区的数据，可能OOM

- 例子：collect算子

  collect算子会拉取rdd中所有数据到driver节点，如果数据量过大，会造成driver的OOM，因此collect只适用于拉取小规模(在executor经过处理)的数据

- 尽量使用reduceByKey代替groupByKey

  reduceByKey 算子会在map端对数据进行聚合(map-side combine)。
  groupByKey不会在map端进行聚合，会造成在shuffle阶段进行大规模数据传输和在shuffle read端的巨大内存压力。


]




---
class:
name:
.left-column[
## RDD Operations
### transformation & action
### transformation
### 合理使用算子
### wordCount Demo
]
.right-column[

```
package sparkApp
import org.apache.spark.{SparkConf, SparkContext}
object SparkWC {

  def main(args: Array[String]){
  val sparkConf = new SparkConf().setAppName(args(0)).setMaster(args(1))
  val sc = new SparkContext(sparkConf)                                  
  sc.textFile(args(2))                                                  
    .flatMap(s => {                                                     
     val parts = s.split(“\\s+")                                       
      parts.map((_,1))                                                  
    })                                                                  
    .reduceByKey(_+_)                                                   
    .saveAsTextFile(args(3)) 
    sc.stop()
    }

  }
```

]
---
class:
name:
.left-column[
## RDD 依赖
### 宽依赖 & 窄依赖

]
.right-column[

<figure class="half">
    <img src="../../imgs/rdd_basics/dependencies.png" width="90%" height="50%">
</figure>

]
---
class:
name:
.left-column[
## RDD 依赖
### 宽依赖 & 窄依赖
### Shuffle 

]
.right-column[

<figure class="half">
    <img src="../../imgs/rdd_basics/shuffle.png" width="72%" height="40%">
</figure>

#### Shuffle是瓶颈所在，shuffle的性能优化十分重要。

- 在write端对map端的分区按照key的hash值进行分块，写入一个partition索引文件（可能存在排序）。

- 磁盘I/O

- 序列化/反序列化

- 网络传输

- 在read端拉取各个partition索引文件对应分区的数据（可能存在排序)。




]

---
class:
name:
.left-column[
## RDD 依赖
### 宽依赖 & 窄依赖
### Shuffle 
### Shuffle性能优化

]
.right-column[
- map-side Combine

- 数据倾斜

- 避免shuffle

]
---
class: 
name:


.left-column[
## RDD与Task
### 分区与Task

]
.right-column[

- 每个stage里面，有若干个 相互独立的Task。

- Task数目等于被操作RDD的分区数。

- 每个Task分别对RDD的一个分区进行一系列操作。

- 在一个executor中，并行的task数目和executor的核数有关。

]
---
class:
name:
.left-column[
## RDD 依赖
### 宽依赖 & 窄依赖
### Shuffle 
### wordCount lineage

]
.right-column[

<figure class="half">
    <img src="../../imgs/rdd_basics/wordcount.png" width="100%" height="50%">
</figure>

]
---
class: 
name:


.left-column[
## RDD与Task
### 分区与Task

]
.right-column[

- 每个stage里面，有若干个 相互独立的Task。

- Task数目等于被操作RDD的分区数。

- 每个Task分别对RDD的一个分区进行一系列操作。

- 在一个executor中，并行的task数目和executor的核数有关。

]

---
class: 
name:


.left-column[
## RDD与Task
### 分区与Task
### 内存模型

]
.right-column[
<center class="half">
    <img src="../../imgs/rdd_basics/memory.png" width="30%" height="50%">
</center>

- 当RDD分区里数据量很大时，每个task占用的执行内存比较大，容易造成内存紧张。
- 当executor内存压力大，可以增大分区数量(减少分区数据量)或者减少executor cpu 核数（减小并行处理task的数量)。



]

---
class: 
name:


.left-column[
## RDD Persist


]
.right-column[
- 适当的缓存数据可以避免重复计算。

  persist(storageLevel)

  cache()=persist(StorageLevel.MEMORY_ONLY)

- 缓存级别

|                     |
| :-----------------: |
|     MEMORY_ONLY     |
|   MEMORY_AND_DISK   |
|   MEMORY_ONLY_SER   |
| MEMORY_AND_DISK_SER |
|      DISK_ONLY      |
|    MEMORY_ONLY_2    |
|  MEMORY_AND_DISK_2  |
|      OFF_HEAP       |



]
---
class: 
name:


.left-column[
## 相关链接


]
.right-column[

- RDD论文

  https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf

- RDD算子介绍

  http://spark.apache.org/docs/latest/rdd-programming-guide.html

- spark 配置

  http://spark.apache.org/docs/latest/configuration.html

- 性能调优

  http://spark.apache.org/docs/latest/tuning.html



]
---
class: center, middle, inverse

# Thanks！
<img style="zoom: 1.0" src="../../imgs/mammut.png"  align="bottom" />



    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create({
        ratio: '16:9',
        slideNumberFormat: 'Slide %current% of %total%',
        // .. or by using a format function
        slideNumberFormat: function (current, total) {
          return ' ' + current + ' of ' + total;
        },
        highlightLanguage: 'scala',
        highlightStyle: 'monokai',
        highlightLines: true,
        // arta, ascetic, dark, default, far, github, googlecode, idea, ir-black, magula, monokai, rainbow, solarized-dark, solarized-light, sunburst, tomorrow, tomorrow-night-blue, tomorrow-night-bright, tomorrow-night, tomorrow-night-eighties, vs, zenburn
        highlightStyle: 'zenburn'
      });
    </script>
  </body>
</html>
